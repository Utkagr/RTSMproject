---
title: Online Buzz Prediction on Twitter
output: github_document
---
```{r include=FALSE}
tdata <- read.csv("/home/utkarsh/rtsm/regression/Twitter/Twitter.data")
names(tdata) <- c("NCD_0","NCD_1","NCD_2","NCD_3","NCD_4","NCD_5","NCD_6",
                  "AI_0","AI_1","AI_2","AI_3","AI_4","AI_5","AI_6",
                  "AS(NA)_0","AS(NA)_1","AS(NA)_2","AS(NA)_3","AS(NA)_4","AS(NA)_5","AS(NA)_6",
                  "BL_0","BL_1","BL_2","BL_3","BL_4","BL_5","BL_6",
                  "NAC_0","NAC_1","NAC_2","NAC_3","NAC_4","NAC_5","NAC_6",
                  "AS(NAC)_0","AS(NAC)_1","AS(NAC)_2","AS(NAC)_3","AS(NAC)_4","AS(NAC)_5","AS(NAC)_6",
                  "CS_0","CS_1","CS_2","CS_3","CS_4","CS_5","CS_6",
                  "AT_0","AT_1","AT_2","AT_3","AT_4","AT_5","AT_6",
                  "NA_0","NA_1","NA_2","NA_3","NA_4","NA_5","NA_6",
                  "ADL_0","ADL_1","ADL_2","ADL_3","ADL_4","ADL_5","ADL_6",
                  "NAD_0","NAD_1","NAD_2","NAD_3","NAD_4","NAD_5","NAD_6","MNAD")
ndata <- NULL
table_res<- NULL
train <- NULL
test <- NULL
model <- NULL
bmodel <- NULL
ndata$NCD <- rowSums(tdata[c(1:7)])
ndata$AI <- rowSums(tdata[c(8:14)])
ndata$AS_NA <- rowSums(tdata[c(15:21)])
ndata$BL <- rowSums(tdata[c(22:28)])
ndata$NAC <- rowSums(tdata[c(29:35)])
ndata$AS_NAC <- rowSums(tdata[c(36:42)])
ndata$CS <- rowSums(tdata[c(43:49)])
ndata$AT <- rowSums(tdata[c(50:56)])
ndata$NAO <- rowSums(tdata[c(57:63)])
ndata$ADL <- rowSums(tdata[c(64:70)])
ndata$NAD <- rowSums(tdata[c(71:77)])
ndata$MNAD <- tdata$MNAD
ndata <- data.frame(ndata)

set.seed(100)
ndata <- ndata[1:198373,]
ndata <- scale(ndata)
ndata <- data.frame(ndata)

#split data
smp_size <- floor(0.70 * nrow(ndata))
train <- ndata[1:smp_size,]
test <- ndata[(1+smp_size):(nrow(ndata)),]

```
Let's take a look on the data.
```{r echo=FALSE}
train[1:5,]
```

## Multicollinearity Diagnostics

#Correlation matrix
```{r echo = FALSE}
cor(train[-c(12)])
```
Most of the features are highly correlated.
We can see that these features have a lot of common information.
-NCD AI AS_NA NAC AS_NAC NAO NAD
-CS BL
-AT ADL

So,we need to eliminate features which donot add much variance to the data.
For that,let's look at the VIF table as well.
```{r include=FALSE}
library(usdm)
```

```{r echo = FALSE}
vif(train[-c(12)])
```
An ideal VIF value is 1.
So,any feature having vif value close to 1 is significant.
A range of 1-5 for the VIF value is preferred.
After 5, the feature is not considered significant.
As we can see, our features lie nowhere near VIF value of 1.

So,this suggests that our features are highly correlated.
And hence,we would have to run Principal Component Analysis on our data because neither correlation table nor VIF analysis is sufficient to differentiate between significant and insignificant features.

#PCA analysis
For PCA,data needs to be:
  scaled
  all numeric
  and without missing values

```{r}
features <- train[-c(12)]
prin_comp <- prcomp(features,scale. = T)
prin_comp$x[1:5,]
dim(prin_comp$x)

```
Now,letâ€™s plot the resultant principal components.
```{r}
biplot(prin_comp,scale = 0)
```
We can see that PC1 and PC2 both come from some features which are marked red.
 i.e. PC1 = a1x1 + a2x2 + a3x3 (say)
 and  PC2 = b1x4 + b2x5 + b3x6 (say)
Basically,PCA's are the resulatant of the correlated features.

Now,let's calculate the variance contribution of every principal component as we aim to find the components which explain the maximum variance. 
This is because, we want to retain as much information as possible using these 
components. So, higher is the explained variance, higher will be the information 
contained in those components.

```{r}
std_dev <- prin_comp$sdev
pr_var <- std_dev^2
prop_varex <- (pr_var/sum(pr_var))*100
prop_varex

```

As we can see,PCA1 contributes app. 59% of the variance and hence is the most important feature.
For more meaningful inference,we make a scree plot.
A scree plot is used to access components or factors which explains the most of variability in the data.
It represents values in descending order.
```{r}
plot(prop_varex, xlab = "Principal Component",
     ylab = "Proportion of Variance Explained",
     type = "b")
```


Here we can see that 6 components approximately 98% variance in the dataset.
For the confirmation check,let's plot a cumulative variance plot.
```{r}
plot(cumsum(prop_varex), xlab = "Principal Component",
     ylab = "Cumulative Proportion of Variance Explained",
     type = "b")
```

The graph clearly shows that we should select 6 features which explains almost 98% of the data.
Hence,we will choose 6 variables from PC1 to PC6 for our model and continue further.
```{r}
pca_data <- data.frame(prin_comp$x[,c(1:6)])
pca_data$MNAD <- train$MNAD
pca_data[1:5,]
```
Now,our training data looks like above.
Let's do the correlation and VIF analysis on this.
```{r}
cor(pca_data[-c(7)])
```
```{r}
vif(pca_data[-c(7)])
```
As we can see, VIF values are close to 1 and correlation matrix also shows that features are independent.
Now, our features are scaled and independent.
Let's apply a regression model now.

##General multiple regression model

```{r}
model=lm(MNAD~.,pca_data)
summary(model)
```
Here,we get an adjusted- R-square value of 0.8547 and all the features are significant as well.
Now, our model seems good.
But, we can still drop a variable to check if our model improves or not.
For that,we can use methods of regression for propagating back-and-forth.

# METHODS OF REGRESSION
1.Forward Selection Method
2.Backward Elimination Method
3.Stepwise Method

For our analysis,we have considered Backward elimination method.
```{r}
bmodel <- step(model, direction = "backward", trace=TRUE )
bmodel

```
As we can see,no features are rejected in the steps of backward-elimination method.
Thus,we can conclude that our model will include all of the 6 variables.
Now,let's take a look at the coefficients and confidence intervals of the features.

#Coefficients
```{r echo=FALSE}
coefficients(model) # model coefficients

```
#Confidence Intervals
```{r echo=FALSE}
confint(model) # CIs for model parameters

```
As we can see,all the coefficients lie in the confidence interval.

Now,let's get to the prediction part.
For prediction,we should not use PCA on train and test separately as their variance is unequal which will result in different vector directions.
Also,we should not combine the training and test set as we donot want our test set to be used in model building.
What we can do is use predict function as shown below.
```{r}
pc_data_test <- predict(prin_comp,test[-c(12)])
pc_data_test <- as.data.frame(pc_data_test)
pc_data_test <- pc_data_test[c(1:6)]
pc_data_test[1:5,]

```
Now,let's predict on the above dataset.
```{r}
pc_data_test$predicted_MNAD <- predict(model,pc_data_test)
pc_data_test$MNAD <- test$MNAD
pc_data_test$residuals <- pc_data_test$MNAD-pc_data_test$predicted_MNAD
pc_data_test[1:5,7:9]
```
We can see that residuals are very less which explains the accuracy of our model.
But,we have to do residual analysis for more accurate results.
Let's calculate the variance of residuals.
```{r}
Se_sq <- sum((pc_data_test$residuals)^2)
n <- nrow(test)
p <- 7
var_res <- Se_sq/(n-p)
std_res <- sqrt(var_res)
std_res
```
Now,let's do Standardized Residual Analysis.
```{r}
pc_data_test$stand_residuals <- pc_data_test$residuals/std_res
mean(pc_data_test$stand_residuals)
var(pc_data_test$stand_residuals)
```
We can see that mean is close to 0 and variance is close to 1.
Let's plot them.
```{r}
plot(pc_data_test$stand_residuals,main = 'Standardized Residuals plot',
     xlab='Observation no.',ylab = 'residuals')
abline(h=5,untf = FALSE)
abline(h=-5,untf = FALSE)
```

Now,we can say that a large standaradized residual(>5,say) potentially indicates an outlier.
```{r}
qqnorm(pc_data_test$stand_residuals,
         ylab="Residuals",
         xlab="Normal Scores",main="Normal Q-Q plot") 
qqline(pc_data_test$stand_residuals)

```

Now,let's plot normal probability plot.
```{r}
y <- (as.numeric(rownames(pc_data_test))-0.5)/nrow(pc_data_test)
x <- sort(pc_data_test$stand_residuals,decreasing = FALSE)
plot(x,y,
     xlab = 'Standardized residuals',
     ylab = 'Probability')
```
This plot is not ideal as it contains a lot of outliers.
Let's take a closer look.
```{r}
plot(x,y,
     xlab = 'Standardized residuals',
     ylab = 'Probability',
     xlim = c(-1,1))
```
This suggests a light-tailed distribution.
